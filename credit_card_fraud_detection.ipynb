{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context\n",
    "It is important that credit card companies are able to recognize fraudulent credit card transactions so that customers are not charged for items that they did not purchase.\n",
    "\n",
    "## Content\n",
    "The datasets contains transactions made by credit cards in **September 2013** by european cardholders.\n",
    "This dataset presents transactions that occurred in two days, where we have **492** frauds out of **284,807** transactions. The dataset is highly unbalanced, the positive class (frauds) account for **0.172%** of all transactions.\n",
    "\n",
    "It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, â€¦ V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise.\n",
    "\n",
    "## Inspiration\n",
    "Identify fraudulent credit card transactions.\n",
    "\n",
    "## Recommendation\n",
    "Given the class imbalance ratio, we recommend measuring the accuracy using the Area Under the Precision-Recall Curve (AUPRC). Confusion matrix accuracy is not meaningful for unbalanced classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score, roc_auc_score, accuracy_score, precision_score\n",
    "from sklearn.metrics import classification_report, recall_score\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed to be fixed. Comment to generate different results every time.\n",
    "seed = 10\n",
    "plt.close('all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
      "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
      "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
      "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
      "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
      "\n",
      "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
      "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
      "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
      "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
      "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
      "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
      "\n",
      "        V26       V27       V28  Amount  Class  \n",
      "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
      "1  0.125895 -0.008983  0.014724    2.69      0  \n",
      "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
      "3 -0.221929  0.062723  0.061458  123.50      0  \n",
      "4  0.502292  0.219422  0.215153   69.99      0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "data = pd.read_csv(\"data/creditcard.csv\")\n",
    "print(data.head())\n",
    "# data = data[:100000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since most of the components are coming from PCA, excluding Time and Amount columns, we will apply RobustScaler to transform these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = RobustScaler()\n",
    "scaler = StandardScaler()\n",
    "data['Amount'] = scaler.fit_transform(data['Amount'].values.reshape(-1, 1))\n",
    "data['Time'] = scaler.fit_transform(data['Time'].values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Time        V1        V2        V3        V4        V5        V6  \\\n",
      "0 -1.996583 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
      "1 -1.996583  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
      "2 -1.996562 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
      "3 -1.996562 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
      "4 -1.996541 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
      "\n",
      "         V7        V8        V9  ...       V21       V22       V23       V24  \\\n",
      "0  0.239599  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928   \n",
      "1 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
      "2  0.791461  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281   \n",
      "3  0.237609  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575   \n",
      "4  0.592941 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267   \n",
      "\n",
      "        V25       V26       V27       V28    Amount  Class  \n",
      "0  0.128539 -0.189115  0.133558 -0.021053  0.244964      0  \n",
      "1  0.167170  0.125895 -0.008983  0.014724 -0.342475      0  \n",
      "2 -0.327642 -0.139097 -0.055353 -0.059752  1.160686      0  \n",
      "3  0.647376 -0.221929  0.062723  0.061458  0.140534      0  \n",
      "4 -0.206010  0.502292  0.219422  0.215153 -0.073403      0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data has a total 31 columns.  \n",
    "Class column is considered Y.  \n",
    "Rest 30 columns taken as X.   \n",
    "This contains normalized Time and Amount column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select data\n",
    "X = data.iloc[:, range(30)]\n",
    "Y = data.Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    284315\n",
      "1       492\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check class imbalance\n",
    "class_count = Y.value_counts()\n",
    "print(class_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset is highly imbalanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset split into 80:20 before applying any class imbalance solution. This measure is taken to prevent data leaking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(227845, 30)\n",
      "(56962, 30)\n",
      "(227845,)\n",
      "(56962,)\n"
     ]
    }
   ],
   "source": [
    "# Train Test split dataset into 80:20 ratio.\n",
    "X_train, X_test, Y_train, Y_test = tts(X, Y,\n",
    "                                       test_size=0.2,\n",
    "                                       random_state=42,\n",
    "                                       shuffle=True)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In class imbalance problem, two common approaches are:\n",
    "1) **Undersampling**: Remove excess data.  \n",
    "2) **Oversampling**: Generate random missing data.\n",
    "\n",
    "We are using Oversampling from imblearn package. There are other approaches also like KNearestNeighbour sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check class imbalance and apply oversampling if count difference is more than 10%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    227451\n",
      "1       394\n",
      "Name: Class, dtype: int64\n",
      "\n",
      "Class imbalance problem. Using Oversampler.\n",
      "1    227451\n",
      "0    227451\n",
      "Name: Class, dtype: int64\n",
      "\n",
      "Data loaded and transformed.\n"
     ]
    }
   ],
   "source": [
    "class_count = Y_train.value_counts()\n",
    "print(class_count)\n",
    "print()\n",
    "\n",
    "if np.abs(Y.value_counts()[0] - Y.value_counts()[1]) / np.sum(Y.value_counts()) > 0.1:\n",
    "    print(\"Class imbalance problem. Using Oversampler.\")\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    X_train, Y_train = ros.fit_resample(X_train, Y_train)\n",
    "\n",
    "class_count = Y_train.value_counts()\n",
    "print(class_count)\n",
    "print()\n",
    "\n",
    "print(\"Data loaded and transformed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create some empty lists to store measured accuracy parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some empty lists\n",
    "recall_list = []\n",
    "precision_list = []\n",
    "f1_list = []\n",
    "accuracy_list = []\n",
    "auc_list = []\n",
    "model_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to print parameters for each classification model and appending list for exporting to a file.\n",
    "def print_parameters(y_real, y_pred):\n",
    "    cm = confusion_matrix(y_real, y_pred)\n",
    "    acc = 100 * accuracy_score(y_real, y_pred)\n",
    "    precision = precision_score(y_real, y_pred)\n",
    "    recall = recall_score(y_real, y_pred)\n",
    "    f1 = f1_score(y_real, y_pred)\n",
    "    auc_roc = roc_auc_score(y_real, y_pred)\n",
    "\n",
    "    accuracy_list.append(acc)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    f1_list.append(f1)\n",
    "    auc_list.append(auc_roc)\n",
    "    model_list.append(model_name)\n",
    "\n",
    "    print(cm)\n",
    "    print(\"Accuracy: %0.2f\" % acc)\n",
    "    print(\"Precision score = %0.2f\" % precision)\n",
    "    print(\"Recall score = %0.2f\" % recall)\n",
    "    print(\"F1 score = %0.2f\" % f1)\n",
    "    print(\"Area Under curve %0.2f\" % auc_roc)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply some Classifier models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Time for Logistic Classifier: 16.414969 s\n",
      "[[55543  1321]\n",
      " [    8    90]]\n",
      "Accuracy: 97.67\n",
      "Precision score = 0.06\n",
      "Recall score = 0.92\n",
      "F1 score = 0.12\n",
      "Area Under curve 0.95\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     56864\n",
      "           1       0.06      0.92      0.12        98\n",
      "\n",
      "    accuracy                           0.98     56962\n",
      "   macro avg       0.53      0.95      0.55     56962\n",
      "weighted avg       1.00      0.98      0.99     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =======================================\n",
    "# Logistic regression\n",
    "start_time = timer()\n",
    "model_name = 'LogisticRegression'\n",
    "clf_log = LogisticRegression(C=0.01,\n",
    "                             random_state=1,\n",
    "                             max_iter=2000,\n",
    "                             n_jobs=-1)\n",
    "clf_log.fit(X_train, Y_train)\n",
    "Y_pred_log = clf_log.predict(X_test)\n",
    "# plot_confusion_matrix(clf_xgb, X_test, Y_test)\n",
    "print(\"==============================\")\n",
    "print('Time for Logistic Classifier: %f s' % (timer() - start_time))\n",
    "print_parameters(Y_test, Y_pred_log)\n",
    "print(classification_report(Y_test, Y_pred_log))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As visible, Precision is worst**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # =======================================\n",
    "# # Using sklearn classifiers\n",
    "# # Support Vector Classifier\n",
    "# start_time = timer()\n",
    "# model_name = 'SupportVectorClassifier'\n",
    "# ker = 'rbf'\n",
    "# clf_svc = SVC(gamma='auto', kernel=ker)  # Kernels available: rbf = Gaus, linear, poly,\n",
    "# clf_svc.fit(X_train, Y_train)\n",
    "# Y_pred_svm = clf_svc.predict(X_test)\n",
    "# # plot_confusion_matrix(clf_svc, X_test, y_test)\n",
    "# end_time = timer()\n",
    "# time_svm = end_time - start_time\n",
    "# print(\"Time for Support Vector Machine: %f s\" % time_svm)\n",
    "# print_parameters(Y_test, Y_pred_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVC stuck because of very large matrix and convex solution takes very long time**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================\n",
    "# Random forest classifier\n",
    "# start_time = timer()\n",
    "# model_name = 'RandomForestGridSearch'\n",
    "# n_estimators = [100]  # [20, 100, 500, 1200]\n",
    "# max_depth = [30]\n",
    "# min_samples_split = [2]  # [2, 15, 50]\n",
    "# min_samples_leaf = [1]  # [1, 2, 5]\n",
    "#\n",
    "# hyperF = dict(n_estimators=n_estimators, max_depth=max_depth,\n",
    "#               min_samples_split=min_samples_split,\n",
    "#               min_samples_leaf=min_samples_leaf)\n",
    "#\n",
    "# forest = RandomForestClassifier()\n",
    "# gridF = GridSearchCV(forest, hyperF, cv=3, scoring='precision_macro', verbose=1, n_jobs=-1)\n",
    "# gridF.fit(X_train, Y_train)\n",
    "#\n",
    "# means = gridF.cv_results_['mean_test_score']\n",
    "# stds = gridF.cv_results_['std_test_score']\n",
    "# for mean, std, params in zip(means, stds, gridF.cv_results_['params']):\n",
    "#     print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "#\n",
    "# print()\n",
    "#\n",
    "# print(\"Detailed classification report:\")\n",
    "# print()\n",
    "# print(\"The model is trained on the full development set.\")\n",
    "# print(\"The scores are computed on the full evaluation set.\")\n",
    "# print()\n",
    "# print(classification_report(Y_test, gridF.predict(X_test)))\n",
    "# print()\n",
    "# print(gridF.best_params_)\n",
    "# print()\n",
    "#\n",
    "# max_depth = gridF.best_params_['max_depth']\n",
    "# min_samples_leaf = gridF.best_params_['min_samples_leaf']\n",
    "# min_samples_split = gridF.best_params_['min_samples_split']\n",
    "# n_estimators = gridF.best_params_['n_estimators']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Time for Random Forrest Classifier: 30.660415 s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.99      0.80      0.88        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.99      0.90      0.94     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "[[56863     1]\n",
      " [   20    78]]\n",
      "Accuracy: 99.96\n",
      "Precision score = 0.99\n",
      "Recall score = 0.80\n",
      "F1 score = 0.88\n",
      "Area Under curve 0.90\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =======================================\n",
    "# Random forest classifier\n",
    "start_time = timer()\n",
    "model_name = 'RandomForest'\n",
    "\n",
    "max_depth = 30\n",
    "n_estimators = 100\n",
    "min_samples_leaf = 1\n",
    "min_samples_split = 2\n",
    "\n",
    "clf_rfc = RandomForestClassifier(n_estimators=n_estimators,\n",
    "                                 max_depth=max_depth,\n",
    "                                 min_samples_split=min_samples_split,\n",
    "                                 min_samples_leaf=min_samples_leaf,\n",
    "                                 random_state=1,\n",
    "                                 n_jobs=-1)\n",
    "clf_rfc.fit(X_train, Y_train)\n",
    "Y_pred_rfc = clf_rfc.predict(X_test)\n",
    "# plot_confusion_matrix(clf_rfc, X_test, Y_test)\n",
    "print(\"==============================\")\n",
    "print('Time for Random Forrest Classifier: %f s' % (timer() - start_time))\n",
    "print(classification_report(Y_test, Y_pred_rfc))\n",
    "print_parameters(Y_test, Y_pred_rfc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision is good, Recall is nice, F1 score is OK**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for Decsion Tree Classifier: 11.391353 s\n",
      "[[56791    73]\n",
      " [   25    73]]\n",
      "Accuracy: 99.83\n",
      "Precision score = 0.50\n",
      "Recall score = 0.74\n",
      "F1 score = 0.60\n",
      "Area Under curve 0.87\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =======================================\n",
    "# Decision Tree Classifier\n",
    "model_name = 'DecisionTree'\n",
    "start_time = timer()\n",
    "clf_dtc = DecisionTreeClassifier(max_depth=30, random_state=0)\n",
    "clf_dtc.fit(X_train, Y_train)\n",
    "Y_pred_dtc = clf_dtc.predict(X_test)\n",
    "# plot_confusion_matrix(clf_dtc, X_test, Y_test)\n",
    "print('Time for Decsion Tree Classifier: %f s' % (timer() - start_time))\n",
    "print_parameters(Y_test, Y_pred_dtc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recall is OK but Precsion is worst**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXtreme Gradient Boost Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Time for XGBoost Classifier: 48.670715 s\n",
      "[[56858     6]\n",
      " [   18    80]]\n",
      "Accuracy: 99.96\n",
      "Precision score = 0.93\n",
      "Recall score = 0.82\n",
      "F1 score = 0.87\n",
      "Area Under curve 0.91\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.93      0.82      0.87        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.96      0.91      0.93     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =======================================\n",
    "# XGBoost\n",
    "start_time = timer()\n",
    "model_name = 'XGBoost'\n",
    "clf_xgb = XGBClassifier(max_depth=100,\n",
    "                        learning_rate=0.2,\n",
    "                        random_state=1,\n",
    "                        n_jobs=-1)\n",
    "clf_xgb.fit(X_train, Y_train)\n",
    "Y_pred_xgb = clf_xgb.predict(X_test)\n",
    "# plot_confusion_matrix(clf_xgb, X_test, Y_test)\n",
    "print(\"==============================\")\n",
    "print('Time for XGBoost Classifier: %f s' % (timer() - start_time))\n",
    "print_parameters(Y_test, Y_pred_xgb)\n",
    "print(classification_report(Y_test, Y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision, Recall and F1 are all decent**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us model a stacking classifier consisting of various models. Let us see if it improves the quality of weak classifier\n",
    "\n",
    "## Stacking Classifier Model\n",
    "1) Random Forest  \n",
    "2) Logistic Regression   \n",
    "3) XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  2.0min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  3.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Time for Stacking Classifier: 480.309735 s\n",
      "[[56862     2]\n",
      " [   19    79]]\n",
      "Accuracy: 99.96\n",
      "Precision score = 0.98\n",
      "Recall score = 0.81\n",
      "F1 score = 0.88\n",
      "Area Under curve 0.90\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.98      0.81      0.88        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.99      0.90      0.94     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =======================================\n",
    "# Stacking Classifier\n",
    "start_time = timer()\n",
    "model_name = 'StackingClassifier'\n",
    "estimators = [\n",
    "    ('RFC', RandomForestClassifier(n_estimators=n_estimators,\n",
    "                                   max_depth=max_depth,\n",
    "                                   min_samples_split=min_samples_split,\n",
    "                                   min_samples_leaf=min_samples_leaf,\n",
    "                                   random_state=1,\n",
    "                                   n_jobs=-1)),\n",
    "    ('Log', LogisticRegression(C=0.1,\n",
    "                               random_state=1,\n",
    "                               max_iter=2000,\n",
    "                               n_jobs=-1)),\n",
    "    # ('SVC', SVC(kernel='rbf', gamma='auto', C=2)),\n",
    "    ('XGB', XGBClassifier(max_depth=100,\n",
    "                          learning_rate=0.2,\n",
    "                          random_state=1,\n",
    "                          n_jobs=-1))\n",
    "]\n",
    "\n",
    "stacking_model = StackingClassifier(estimators=estimators,\n",
    "                                    final_estimator=LogisticRegression(),\n",
    "                                    verbose=1\n",
    "                                    )\n",
    "\n",
    "stacking_model.fit(X_train, Y_train)\n",
    "Y_pred_log = stacking_model.predict(X_test)\n",
    "# plot_confusion_matrix(clf_xgb, X_test, Y_test)\n",
    "print(\"==============================\")\n",
    "print('Time for Stacking Classifier: %f s' % (timer() - start_time))\n",
    "print_parameters(Y_test, Y_pred_log)\n",
    "print(classification_report(Y_test, Y_pred_log))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quality does not improve. XGB still produces better result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ModelName</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>AreaUnderCurve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>97.666866</td>\n",
       "      <td>0.063785</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>0.119284</td>\n",
       "      <td>0.947568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>99.963133</td>\n",
       "      <td>0.987342</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.897950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>99.827955</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.744898</td>\n",
       "      <td>0.598361</td>\n",
       "      <td>0.871807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>99.957867</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.908111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>StackingClassifier</td>\n",
       "      <td>99.963133</td>\n",
       "      <td>0.975309</td>\n",
       "      <td>0.806122</td>\n",
       "      <td>0.882682</td>\n",
       "      <td>0.903044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ModelName   Accuracy  Precision    Recall        F1  \\\n",
       "0  LogisticRegression  97.666866   0.063785  0.918367  0.119284   \n",
       "1        RandomForest  99.963133   0.987342  0.795918  0.881356   \n",
       "2        DecisionTree  99.827955   0.500000  0.744898  0.598361   \n",
       "3             XGBoost  99.957867   0.930233  0.816327  0.869565   \n",
       "4  StackingClassifier  99.963133   0.975309  0.806122  0.882682   \n",
       "\n",
       "   AreaUnderCurve  \n",
       "0        0.947568  \n",
       "1        0.897950  \n",
       "2        0.871807  \n",
       "3        0.908111  \n",
       "4        0.903044  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe of results\n",
    "d = {'ModelName': model_list,\n",
    "     'Accuracy': accuracy_list,\n",
    "     'Precision': precision_list,\n",
    "     'Recall': recall_list,\n",
    "     'F1': f1_list,\n",
    "     'AreaUnderCurve': auc_list}\n",
    "measures = pd.DataFrame(d)\n",
    "measures.to_csv('results.csv', index=False)\n",
    "measures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Five models were applied for this classification problem.\n",
    "* Since the data is highly imbalanced, and positive (fraud) events are low, **Accuracy** is not a good metric to trust. In a simple case, if all classes are considered 0, Accuracy will be close to 98%.     \n",
    "* **Recall** and **Precision** are important metric in this case. \n",
    "* Another derived metric, **Area Under Curve** is also calcualted for improving classification.\n",
    "\n",
    "* Logistic Regression and Single Decision Tree have excellent Recall but Precsion is bad.  \n",
    "* Random Forest and XGBoost are both good classifiers. **XGBoost** outperforms all other classifiers.  \n",
    "* Stacking model did not improve quality, although taking enormous time to perform calculations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best metrics achieved for XGBoost at Recall=0.816 and AUC=0.908"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
